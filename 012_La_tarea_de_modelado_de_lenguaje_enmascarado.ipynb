{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **La tarea de modelado del lenguaje enmascarado**"
      ],
      "metadata": {
        "id": "b5BNo5ZJmQZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Ht-If1yPmZqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOo9qsACmDnn"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForMaskedLM, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# El paquete Transformers llega con varios \"heads\" estándar además del modelo BERT estándar\n",
        "bert_lm = BertForMaskedLM.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "P4CQyqQNoGXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_lm   #inspecciona el modelo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCcAqoNOoOB6",
        "outputId": "50d28347-a8ee-4dfa-cf90-db744c70eba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipelines en transformers toma como entradas modelos/tokenizadores y son el modo más sencillo de automatizar varias tareas\n",
        "#Podemos realizar una tarea de modelado de lenguaje auto-codificado\n",
        "nlp = pipeline(\"fill-mask\", model='bert-base-cased') #podemos también usar \"model=bert_lm\" con el mismo resultado\n"
      ],
      "metadata": {
        "id": "K6u24aSzoWlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(nlp.model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAgpRITYobvo",
        "outputId": "24a59a7f-a088-4b15-9388-3eaeadf8bf9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bert.modeling_bert.BertForMaskedLM"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.tokenizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V1CHR8-ogQs",
        "outputId": "361b2dcf-e615-472e-c437-c4ce9b96af67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(nlp.model))\n",
        "preds = nlp(f\"If you don't {nlp.tokenizer.mask_token} at the sign, you will get a ticket.\")\n",
        "print(\"If you don't *** at the sign, you will get a ticket.\")\n",
        "for p in preds:\n",
        "    print(f\"Token: {p['token_str']}. Score: {100*p['score']:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O7YX8yxon3u",
        "outputId": "63707386-2b96-41fb-bc0f-82d6baa50367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n",
            "If you don't *** at the sign, you will get a ticket.\n",
            "Token: stop. Score: 51.10%\n",
            "Token: look. Score: 38.41%\n",
            "Token: arrive. Score: 1.11%\n",
            "Token: glance. Score: 1.05%\n",
            "Token: turn. Score: 0.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(nlp.model))\n",
        "preds = nlp(f\"The {nlp.tokenizer.mask_token} shines brightly.\")\n",
        "print(\"The *** shine brightly .\")\n",
        "for p in preds:\n",
        "    print(f\"Token: {p['token_str']}. Score: {100*p['score']:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzI329vtqCAv",
        "outputId": "a4b60453-478d-456f-e115-f2094ee21aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n",
            "The *** shine brightly .\n",
            "Token: sun. Score: 22.87%\n",
            "Token: moon. Score: 13.84%\n",
            "Token: light. Score: 5.72%\n",
            "Token: sky. Score: 2.69%\n",
            "Token: room. Score: 2.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iY3gLXgwxHB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(nlp.model))\n",
        "preds = nlp(f\"This morning the {nlp.tokenizer.mask_token} shines very bright.\")\n",
        "print(\"This morning the *** shines very bright .\")\n",
        "for p in preds:\n",
        "    print(f\"Token: {p['token_str']}. Score: {100*p['score']:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e614bf-5c99-459f-bf64-62bfe5c18fd7",
        "id": "TvO7raC2xKyf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n",
            "This morning the *** shines very bright .\n",
            "Token: sun. Score: 58.93%\n",
            "Token: moon. Score: 16.46%\n",
            "Token: sky. Score: 5.04%\n",
            "Token: light. Score: 2.28%\n",
            "Token: day. Score: 0.85%\n"
          ]
        }
      ]
    }
  ]
}